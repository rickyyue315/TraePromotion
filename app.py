import streamlit as st
import pandas as pd
import numpy as np
import openpyxl
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from datetime import datetime
import io

# --- æ—¥èªŒè¨˜éŒ„è¨­ç½® ---
logging.basicConfig(filename='app.log', level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')

# --- å‡½æ•¸å®šç¾© ---
def find_sheet_name(sheet_names, candidates):
    """å¾å€™é¸åˆ—è¡¨ä¸­æŸ¥æ‰¾æœ‰æ•ˆçš„å·¥ä½œè¡¨åç¨±ã€‚"""
    for name in candidates:
        if name in sheet_names:
            return name
    return None

def load_data(file_a, file_b):
    """è¼‰å…¥ã€é©—è­‰ã€æ¸…ç†ä¸¦åˆä½µå…©å€‹ä¸Šå‚³çš„ Excel æª”æ¡ˆã€‚"""
    try:
        # --- æª”æ¡ˆ A è™•ç† ---
        df_a = pd.read_excel(file_a, sheet_name=0, dtype={'Article': str, 'Site': str})
        required_cols_a = [
            'Article', 'Article Description', 'RP Type', 'Site', 'MOQ', 
            'SaSa Net Stock', 'Pending Received', 'Safety Stock', 
            'Last Month Sold Qty', 'MTD Sold Qty', 'Supply source', 'Description p. group'
        ]
        if not all(col in df_a.columns for col in required_cols_a):
            missing_cols = [col for col in required_cols_a if col not in df_a.columns]
            st.error(f"æª”æ¡ˆ A ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing_cols)}")
            return None, None

        # --- æª”æ¡ˆ B è™•ç† ---
        xls_b = pd.ExcelFile(file_b)
        sheet_names_b = xls_b.sheet_names

        sheet1_name = find_sheet_name(sheet_names_b, ['Sheet1', 'Sheet 1'])
        sheet2_name = find_sheet_name(sheet_names_b, ['Sheet2', 'Sheet 2'])

        if not sheet1_name or not sheet2_name:
            st.error("æª”æ¡ˆ B å¿…é ˆåŒ…å« 'Sheet1' (æˆ– 'Sheet 1') å’Œ 'Sheet2' (æˆ– 'Sheet 2')ã€‚")
            return None, None
        
        df_b1 = pd.read_excel(xls_b, sheet1_name, dtype={'Article': str})
        required_cols_b1 = ['Group No.', 'Article', 'SKU Target', 'Target Type', 'Promotion Days', 'Target Cover Days']
        if not all(col in df_b1.columns for col in required_cols_b1):
            missing_cols = [col for col in required_cols_b1 if col not in df_b1.columns]
            st.error(f"æª”æ¡ˆ B çš„ {sheet1_name} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing_cols)}")
            return None, None

        df_b2 = pd.read_excel(xls_b, sheet2_name, dtype={'Site': str})
        required_cols_b2 = ['Site', 'Shop Target(HK)', 'Shop Target(MO)', 'Shop Target(ALL)']
        if not all(col in df_b2.columns for col in required_cols_b2):
            missing_cols = [col for col in required_cols_b2 if col not in df_b2.columns]
            st.error(f"æª”æ¡ˆ B çš„ {sheet2_name} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing_cols)}")
            return None, None

        # --- æ•¸æ“šæ¸…ç†èˆ‡é è™•ç† ---
        df_a['Notes'] = ''
        
        # æ¸…ç†å­—ä¸²æ¬„ä½
        for col in ['Article', 'Site']:
            if col in df_a.columns:
                df_a[col] = df_a[col].str.strip()
        if 'Article' in df_b1.columns:
            df_b1['Article'] = df_b1['Article'].str.strip()
        if 'Site' in df_b2.columns:
            df_b2['Site'] = df_b2['Site'].str.strip()

        # è™•ç†æ•¸å€¼æ¬„ä½
        numeric_cols_a = ['MOQ', 'SaSa Net Stock', 'Pending Received', 'Safety Stock', 'Last Month Sold Qty', 'MTD Sold Qty']
        for col in numeric_cols_a:
            if col in df_a.columns:
                df_a['Notes'] += np.where(pd.to_numeric(df_a[col], errors='coerce').isnull(), f'{col} åŒ…å«ç„¡æ•ˆå€¼; ', '')
                df_a[col] = pd.to_numeric(df_a[col], errors='coerce').fillna(0).astype(int)
                df_a['Notes'] += np.where(df_a[col] < 0, f'{col} ä¿®æ­£ç‚º 0; ', '')
                df_a[col] = np.where(df_a[col] < 0, 0, df_a[col])

        # è™•ç†éŠ·é‡ç•°å¸¸
        if 'Last Month Sold Qty' in df_a.columns:
            df_a['Notes'] += np.where(df_a['Last Month Sold Qty'] > 100000, 'éŠ·é‡ç•°å¸¸èª¿æ•´; ', '')
            df_a['Last Month Sold Qty'] = np.where(df_a['Last Month Sold Qty'] > 100000, 100000, df_a['Last Month Sold Qty'])

        # --- åˆä½µæ•¸æ“š ---
        df_merged = pd.merge(df_a, df_b1, on='Article', how='left')
        df_merged = pd.merge(df_merged, df_b2, on='Site', how='left')

        # å¡«å……åˆä½µå¾Œç”¢ç”Ÿçš„ NaN
        fill_cols = list(df_b1.columns) + list(df_b2.columns)
        fill_cols = [c for c in fill_cols if c not in ['Article', 'Site']]
        
        for col in fill_cols:
            if col in df_merged.columns:
                if pd.api.types.is_numeric_dtype(df_merged[col]):
                    df_merged[col] = df_merged[col].fillna(0)
                else:
                    df_merged[col] = df_merged[col].fillna('')
        
        if 'Group No.' in df_merged.columns:
             df_merged['Notes'] += np.where(df_merged['Group No.'].fillna('') == '', 'æœªåŒ¹é…åˆ°æ¨å»£ç›®æ¨™; ', '')

        return df_merged, None

    except Exception as e:
        st.error(f"è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logging.error(f"File processing error: {e}", exc_info=True)
        return None, None

def calculate_demand(df, lead_time):
    """è¨ˆç®—æ¨å»£è²¨é‡éœ€æ±‚ã€‚"""
    try:
        if df is None or df.empty:
            return pd.DataFrame(), pd.DataFrame()

        # è¤‡è£½æ•¸æ“šæ¡†ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
        df_calc = df.copy()

        # 1. è¨ˆç®—æ¯æ—¥éŠ·å”®ç‡
        df_calc['Daily Sales Rate'] = (df_calc['Last Month Sold Qty'] / 30).apply(lambda x: max(0, x))

        # 2. ç¢ºå®šæ¨å»£ç›®æ¨™ä¿‚æ•¸
        df_calc['Site Target %'] = df_calc.apply(
            lambda row: row['Shop Target(HK)'] if row['Target Type'] == 'HK'
            else (row['Shop Target(MO)'] if row['Target Type'] == 'MO'
                  else (row['Shop Target(ALL)'] if row['Target Type'] == 'ALL' else 0)),
            axis=1
        )

        # 3. è¨ˆç®—æ—¥å¸¸éŠ·å”®éœ€æ±‚
        df_calc['Regular Demand'] = df_calc['Daily Sales Rate'] * (df_calc['Target Cover Days'] + lead_time)

        # 4. è¨ˆç®—æ¨å»£ç‰¹å®šéœ€æ±‚
        df_calc['Promo Demand'] = df_calc['SKU Target'] * df_calc['Site Target %']

        # 5. è¨ˆç®—ç¸½éœ€æ±‚
        # å°æ–¼å¤š SKU çµ„ï¼Œéœ€è¦å…ˆèšåˆ
        group_sku_counts = df_calc.groupby('Group No.')['Article'].nunique()
        multi_sku_groups = group_sku_counts[group_sku_counts > 1].index

        # åˆå§‹åŒ– Total Demand
        df_calc['Total Demand'] = 0

        # å–® SKU çµ„
        single_sku_mask = ~df_calc['Group No.'].isin(multi_sku_groups)
        df_calc.loc[single_sku_mask, 'Total Demand'] = df_calc.loc[single_sku_mask, 'Regular Demand'] + df_calc.loc[single_sku_mask, 'Promo Demand']

        # å¤š SKU çµ„
        if not multi_sku_groups.empty:
            # æŒ‰ Group No. å’Œ Site èšåˆ Regular Demand
            agg_regular_demand = df_calc[df_calc['Group No.'].isin(multi_sku_groups)].groupby(['Group No.', 'Site'])['Regular Demand'].sum().reset_index()
            agg_regular_demand.rename(columns={'Regular Demand': 'Aggregated Regular Demand'}, inplace=True)

            # å°‡èšåˆå¾Œçš„éœ€æ±‚åˆä½µå›ä¸»æ•¸æ“šæ¡†
            df_calc = pd.merge(df_calc, agg_regular_demand, on=['Group No.', 'Site'], how='left')
            df_calc['Aggregated Regular Demand'].fillna(0, inplace=True)

            # è¨ˆç®—å¤š SKU çµ„çš„ Total Demand
            multi_sku_mask = df_calc['Group No.'].isin(multi_sku_groups)
            df_calc.loc[multi_sku_mask, 'Total Demand'] = df_calc.loc[multi_sku_mask, 'Aggregated Regular Demand'] + df_calc.loc[multi_sku_mask, 'Promo Demand']
            df_calc.drop(columns=['Aggregated Regular Demand'], inplace=True)


        # 6. è¨ˆç®—æ·¨éœ€æ±‚
        df_calc['Net Demand'] = df_calc['Total Demand'] - (df_calc['SaSa Net Stock'] + df_calc['Pending Received']) + df_calc['Safety Stock']

        # 7. è¨ˆç®—æ´¾è²¨å»ºè­°
        # æ–°é‚è¼¯: æ´¾è²¨æ•¸é‡éœ€ç‚º MOQ çš„å€æ•¸ï¼Œä¸”ä¸å°æ–¼ MOQ
        
        # æ­¥é©Ÿ 1: ç¢ºå®šåŸºç¤æ´¾è²¨é‡ï¼Œè‡³å°‘ç‚º Net Demand å’Œ MOQ ä¸­çš„è¼ƒå¤§è€…
        base_dispatch_qty = np.maximum(df_calc['Net Demand'], df_calc['MOQ'])
        
        # æ­¥é©Ÿ 2: å°‡åŸºç¤æ´¾è²¨é‡å‘ä¸Šå–æ•´è‡³ MOQ çš„æœ€æ¥è¿‘å€æ•¸
        moq = df_calc['MOQ']
        # ç‚ºé¿å…é™¤ä»¥é›¶çš„éŒ¯èª¤ï¼Œåªåœ¨ MOQ > 0 æ™‚åŸ·è¡Œè¨ˆç®—
        final_dispatch_qty = np.where(
            moq > 0,
            np.ceil(base_dispatch_qty / moq) * moq,
            base_dispatch_qty # è‹¥ MOQ ç‚º 0ï¼Œå‰‡å›é€€åˆ°åŸºç¤æ´¾è²¨é‡
        )
        
        # æ­¥é©Ÿ 3: åƒ…å° RP Type ç‚º 'RF' çš„é …ç›®æ‡‰ç”¨æ­¤é‚è¼¯
        df_calc['Suggested Dispatch Qty'] = np.where(
            df_calc['RP Type'] == 'RF',
            final_dispatch_qty,
            0
        )
        
        # æ­¥é©Ÿ 4: æ¸…ç†æ•¸æ“šï¼Œç¢ºä¿ç‚ºéè² æ•´æ•¸
        df_calc['Suggested Dispatch Qty'] = df_calc['Suggested Dispatch Qty'].clip(lower=0).fillna(0).astype(int)

        # 8. ç¢ºå®šæ´¾è²¨é¡å‹
        df_calc['Dispatch Type'] = np.where(
            df_calc['Site'] == 'D001',
            'D001',
            np.where(
                df_calc['RP Type'] == 'ND',
                'ND',
                np.where(
                    df_calc['Supply source'].isin([1, 4]),
                    'Buyeréœ€è¦è¨‚è²¨',
                    np.where(df_calc['Supply source'] == 2, 'éœ€ç”Ÿæˆ DN', '')
                )
            )
        )
        
        # æ›´æ–° Notes
        df_calc['Notes'] += f'Lead Time={lead_time}æ—¥; '

        # 9. èšåˆæ‘˜è¦è¡¨ (æŒ‰ Group No. å’Œ SKU)
        # 1. åˆ†é›¢ D001 å’Œé D001 æ•¸æ“š
        df_non_d001 = df_calc[df_calc['Site'] != 'D001'].copy()
        df_d001 = df_calc[df_calc['Site'] == 'D001'].copy()

        # 2. å¾é D001 æ•¸æ“šå‰µå»ºåŸºç¤ç¸½çµ
        summary_base = df_non_d001.groupby(['Group No.', 'Article']).agg(
            Total_Demand=('Total Demand', 'sum'),
            Total_Stock=('SaSa Net Stock', 'sum'),
            Total_Pending=('Pending Received', 'sum'),
            Total_Dispatch=('Suggested Dispatch Qty', 'sum')
        ).reset_index()

        # 3. å‰µå»º D001 åº«å­˜ç¸½çµ
        if not df_d001.empty:
            d001_stock_cols = ['SaSa Net Stock', 'In Quality Insp.', 'Blocked', 'Pending Received']
            for col in d001_stock_cols:
                if col not in df_d001.columns:
                    df_d001[col] = 0
            
            d001_summary = df_d001.groupby(['Group No.', 'Article']).agg(
                D001_SaSa_Net_Stock=('SaSa Net Stock', 'sum'),
                D001_In_Quality_Insp=('In Quality Insp.', 'sum'),
                D001_Blocked=('Blocked', 'sum'),
                D001_Pending_Received=('Pending Received', 'sum')
            ).reset_index()
        else:
            d001_summary = pd.DataFrame(columns=['Group No.', 'Article', 'D001_SaSa_Net_Stock', 'D001_In_Quality_Insp', 'D001_Blocked', 'D001_Pending_Received'])

        # 4. åˆä½µåŸºç¤ç¸½çµå’Œ D001 åº«å­˜
        summary_final = pd.merge(summary_base, d001_summary, on=['Group No.', 'Article'], how='left')

        # 5. å¡«å…… NaN ä¸¦è¨­ç½®æ•¸æ“šé¡å‹
        fill_cols = ['D001_SaSa_Net_Stock', 'D001_In_Quality_Insp', 'D001_Blocked', 'D001_Pending_Received']
        for col in fill_cols:
            summary_final[col] = summary_final[col].fillna(0).astype(int)

        # 6. æ·»åŠ è¨ˆç®—æ¬„ä½
        summary_final['Total_Stock_Available'] = summary_final['Total_Stock'] + summary_final['Total_Pending']
        
        # æ›´æ–° Out_of_Stock_Warning é‚è¼¯
        # å„ªå…ˆç´š 1: æª¢æŸ¥ D001 æ˜¯å¦æœ‰è¶³å¤ çš„åº«å­˜ä¾†æ‡‰å°ç¸½æ´¾è²¨é‡
        # å„ªå…ˆç´š 2: å¦‚æœ D001 åº«å­˜å……è¶³ï¼Œå†æª¢æŸ¥é D001 é–€å¸‚çš„åº«å­˜æ˜¯å¦æ»¿è¶³å…¶éœ€æ±‚
        summary_final['Out_of_Stock_Warning'] = np.where(
            summary_final['Total_Dispatch'] > summary_final['D001_SaSa_Net_Stock'],
            'D001 ç¼ºè²¨',
            np.where(summary_final['Total_Demand'] > summary_final['Total_Stock_Available'], 'Y', 'N')
        )

        # å°‡ 'Article' é‡å‘½åç‚º 'SKU'
        summary_final.rename(columns={'Article': 'SKU'}, inplace=True)

        # é‡æ–°æ’åºæ¬„ä½
        final_cols = [
            'Group No.', 'SKU', 'Total_Demand', 'Total_Stock', 'Total_Pending', 'Total_Stock_Available', 'Total_Dispatch',
            'D001_SaSa_Net_Stock', 'D001_In_Quality_Insp', 'D001_Blocked', 'D001_Pending_Received', 'Out_of_Stock_Warning'
        ]
        summary_final = summary_final[final_cols]

        return df_calc, summary_final
    except Exception as e:
        st.error(f"è¨ˆç®—éœ€æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logging.error(f"Demand calculation error: {e}", exc_info=True)
        return pd.DataFrame(), pd.DataFrame()


# --- Streamlit UI ---
st.set_page_config(layout="wide", page_title="é›¶å”®æ¨å»£ç›®æ¨™æª¢è¦–åŠæ´¾è²¨ç³»çµ±")

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("é–‹ç™¼è€…è³‡è¨Š")
    st.write("å§“åï¼šRicky")
    st.write("ç•¶å‰ç‰ˆæœ¬ï¼šv1.0")
    
    st.header("åƒæ•¸è¨­å®š")
    lead_time = st.slider("è‡ªè¨‚ Lead Time (æ—¥)", min_value=2.0, max_value=5.0, value=2.0, step=0.5)

    st.header("æª”æ¡ˆä¸Šå‚³æ³¨æ„äº‹é …")
    st.info("è«‹ç¢ºä¿ä¸Šå‚³çš„æª”æ¡ˆç¬¦åˆä»¥ä¸‹æ ¼å¼è¦æ±‚ï¼š")
    with st.expander("æª”æ¡ˆ A (åº«å­˜èˆ‡éŠ·å”®) æ³¨æ„äº‹é …", expanded=False):
        st.markdown("""
        - **å¿…è¦æ¬„ä½**: å¿…é ˆåŒ…å« `Article`, `Site`, `SaSa Net Stock`, `Pending Received`, `MOQ`, `RP Type`, `Last Month Sold Qty` ç­‰ã€‚
        - **è³‡æ–™æ ¼å¼**: 
            - `Article` å’Œ `Site` æœƒè‡ªå‹•æ¸…é™¤å‰å¾Œç©ºæ ¼ã€‚
            - æ•¸å€¼æ¬„ä½ (å¦‚åº«å­˜ã€éŠ·é‡) ä¸­çš„éæ•¸å­—æˆ–è² æ•¸æœƒè¢«è¦–ç‚º 0ã€‚
        """)
    with st.expander("æª”æ¡ˆ B (æ¨å»£ç›®æ¨™) æ³¨æ„äº‹é …", expanded=False):
        st.markdown("""
        - **å·¥ä½œè¡¨**: å¿…é ˆåŒ…å« `Sheet1` å’Œ `Sheet2`ã€‚
        - **Sheet1 æ¬„ä½**: éœ€æœ‰ `Group No.`, `Article`, `SKU Target` ç­‰ã€‚
        - **Sheet2 æ¬„ä½**: éœ€æœ‰ `Site`, `Shop Target(HK)` ç­‰ã€‚
        """)

# --- ä¸»å€åŸŸ ---
st.title("é›¶å”®æ¨å»£ç›®æ¨™æª¢è¦–åŠæ´¾è²¨ç³»çµ±")

# --- æª”æ¡ˆä¸Šå‚³ ---
uploaded_file_a = st.file_uploader("ä¸Šå‚³åº«å­˜èˆ‡éŠ·å”®æª”æ¡ˆ (A)", type=["xlsx"])
uploaded_file_b = st.file_uploader("ä¸Šå‚³æ¨å»£ç›®æ¨™æª”æ¡ˆ (B)", type=["xlsx"])

# åˆå§‹åŒ– session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_merged = None
    st.session_state.results = None
    st.session_state.summary = None

if uploaded_file_a and uploaded_file_b:
    df_merged, _ = load_data(uploaded_file_a, uploaded_file_b)
    if df_merged is not None:
        st.session_state.df_merged = df_merged
        st.session_state.data_loaded = True

# --- è³‡æ–™é è¦½ ---
with st.expander("è³‡æ–™é è¦½ (å‰ 10 è¡Œ)", expanded=False):
    if st.session_state.data_loaded:
        st.dataframe(st.session_state.df_merged.head(10), use_container_width=True)
    else:
        st.info("è«‹ä¸Šå‚³å…©å€‹æª”æ¡ˆä»¥é è¦½è³‡æ–™ã€‚")

# --- åˆ†æè§¸ç™¼ ---
if st.button("é–‹å§‹åˆ†æ"):
    if st.session_state.data_loaded:
        progress_bar = st.progress(0, text="åˆ†æä¸­ï¼Œè«‹ç¨å€™...")
        
        # åŸ·è¡Œè¨ˆç®—
        results, summary = calculate_demand(st.session_state.df_merged, lead_time)
        st.session_state.results = results
        st.session_state.summary = summary
        
        progress_bar.progress(100, text="åˆ†æå®Œæˆï¼")
        st.success("âœ… åˆ†æå®Œæˆï¼")
    else:
        st.error("éŒ¯èª¤ï¼šè«‹å…ˆä¸Šå‚³å…©å€‹å¿…è¦çš„ Excel æª”æ¡ˆã€‚")

# --- çµæœé¡¯ç¤º ---
with st.expander("è©³ç´°è¨ˆç®—çµæœ", expanded=True):
    if st.session_state.results is not None:
        st.dataframe(st.session_state.results, use_container_width=True)
    else:
        st.info("é»æ“Šã€Œé–‹å§‹åˆ†æã€ä»¥ç”Ÿæˆçµæœã€‚")

with st.expander("ç¸½çµå ±å‘Š", expanded=True):
    if st.session_state.summary is not None:
        st.dataframe(st.session_state.summary, use_container_width=True)
    else:
        st.info("é»æ“Šã€Œé–‹å§‹åˆ†æã€ä»¥ç”Ÿæˆç¸½çµå ±å‘Šã€‚")

def create_visualizations(results_df, summary_df):
    """æ ¹æ“šåˆ†æçµæœå‰µå»ºä¸¦é¡¯ç¤ºå¤šå€‹è¦–è¦ºåŒ–åœ–è¡¨ã€‚"""
    st.header("Visualization Analysis")

    if results_df.empty:
        st.info("No data available for visualization.")
        return

    # --- éæ¿«å™¨ ---
    group_options = ["All"] + sorted(results_df['Group No.'].unique().tolist())
    selected_group = st.selectbox("Select Group No. to analyze", options=group_options)

    # æ ¹æ“šé¸æ“‡éæ¿«æ•¸æ“š
    if selected_group != "All":
        filtered_results = results_df[results_df['Group No.'] == selected_group]
        filtered_summary = summary_df[summary_df['Group No.'] == selected_group]
    else:
        filtered_results = results_df
        filtered_summary = summary_df

    if filtered_results.empty:
        st.warning("No data to display for the selected group.")
        return

    # --- åœ–è¡¨ç”Ÿæˆ ---
    # 1. æŸ±ç‹€åœ– (SKU éœ€æ±‚ vs åº«å­˜, ä¸å« D001)
    st.subheader("SKU Demand vs. Stock (excluding D001)")
    
    # éæ¿«æ‰ D001
    chart_data = filtered_results[filtered_results['Site'] != 'D001'].copy()
    
    if not chart_data.empty:
        # è¨ˆç®—æ¯å€‹ SKU çš„ç¸½éœ€æ±‚å’Œç¸½åº«å­˜
        chart_data['Stock Available'] = chart_data['SaSa Net Stock'] + chart_data['Pending Received']
        sku_plot_data = chart_data.groupby('Article').agg({
            'Total Demand': 'sum',
            'Stock Available': 'sum'
        }).reset_index()

        fig1, ax1 = plt.subplots()
        sku_plot_data.plot(x='Article', y=['Total Demand', 'Stock Available'], kind='bar', ax=ax1)
        ax1.set_title(f"Group: {selected_group}")
        ax1.set_ylabel("Quantity")
        ax1.tick_params(axis='x', rotation=90)
        st.pyplot(fig1)
        st.caption("This chart compares total demand vs. available stock for each SKU (D001 excluded).")
    else:
        st.info("No data available for this chart after excluding D001.")

    # 2. æ·¨éœ€æ±‚ç†±åœ–
    st.subheader("Net Demand Heatmap (by Site and Article, excluding D001)")
    heatmap_filtered_results = filtered_results[filtered_results['Site'] != 'D001']
    heatmap_data = heatmap_filtered_results.pivot_table(index='Site', columns='Article', values='Net Demand', aggfunc='sum')
    if not heatmap_data.empty:
        # å¦‚æœæ•¸æ“šé»å¤ªå¤šï¼Œé€²è¡ŒæŠ½æ¨£
        if heatmap_data.size > 1000:
            st.warning("Data points exceed 1000. Showing a sample of the data.")
            sampled_cols = np.random.choice(heatmap_data.columns, size=min(50, len(heatmap_data.columns)), replace=False)
            heatmap_data = heatmap_data[sampled_cols]

        fig3, ax3 = plt.subplots(figsize=(12, max(6, len(heatmap_data.index) * 0.5)))
        sns.heatmap(heatmap_data, annot=True, fmt=".0f", cmap="viridis", ax=ax3)
        ax3.set_title(f"Group: {selected_group}")
        st.pyplot(fig3)
        st.caption("This heatmap shows the net demand for each article at each site (D001 excluded). Higher values indicate greater demand.")
    else:
        st.info("No net demand data available to generate a heatmap for this group (D001 excluded).")

def export_to_excel(raw_df, results_df, summary_df):
    """å°‡æ•¸æ“šå°å‡ºåˆ°ä¸€å€‹å¤šå·¥ä½œè¡¨çš„ Excel æª”æ¡ˆä¸­ã€‚"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        raw_df.to_excel(writer, sheet_name='Raw Data', index=False)
        results_df.to_excel(writer, sheet_name='Calculation Results', index=False)
        summary_df.to_excel(writer, sheet_name='Summary', index=False)
    
    processed_data = output.getvalue()
    return processed_data

# --- è¦–è¦ºåŒ–åœ–è¡¨ ---
with st.expander("è¦–è¦ºåŒ–åœ–è¡¨", expanded=True):
    if st.session_state.results is not None:
        create_visualizations(st.session_state.results, st.session_state.summary)
    else:
        st.info("é»æ“Šã€Œé–‹å§‹åˆ†æã€ä»¥ç”Ÿæˆåœ–è¡¨ã€‚")

# --- åŒ¯å‡ºåŠŸèƒ½ ---
with st.expander("åŒ¯å‡ºåˆ†æçµæœ", expanded=False):
    if st.session_state.results is not None:
        current_date = datetime.now().strftime("%Y%m%d")
        file_name = f"Promotion_Demand_Report_{current_date}.xlsx"
        
        excel_data = export_to_excel(
            st.session_state.df_merged,
            st.session_state.results,
            st.session_state.summary
        )
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
            data=excel_data,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.info("é»æ“Šã€Œé–‹å§‹åˆ†æã€ä»¥ç”Ÿæˆå¯åŒ¯å‡ºçš„å ±å‘Šã€‚")

# --- ä¾è³´æª¢æŸ¥ ---
try:
    import openpyxl
    import matplotlib
    import seaborn
except ImportError:
    st.error("ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼Œè«‹æ ¹æ“š requirements.txt æª”æ¡ˆå®‰è£ã€‚")